{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2085169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c87b254a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Users/dinakarreddy/anaconda3/lib/python3.11/site-packages (0.8.10)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bc925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a54ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to connect to Cassandra\n",
    "def connect_to_cassandra():\n",
    "    cloud_config = {\n",
    "        'secure_connect_bundle': 'secure-connect-salesdb.zip'\n",
    "    }\n",
    "    with open(\"salesdb-token.json\") as f:\n",
    "        secrets = json.load(f)\n",
    "\n",
    "    CLIENT_ID = secrets[\"clientId\"]\n",
    "    CLIENT_SECRET = secrets[\"secret\"]\n",
    "\n",
    "    auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
    "    cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "    session = cluster.connect()\n",
    "    return session, cluster  # Returns both session and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368c12eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(session, keyspace, table, df):\n",
    "    df['Order Date'] = pd.to_datetime(df['Order Date']).dt.strftime('%Y-%m-%d')\n",
    "    df['Ship Date'] = pd.to_datetime(df['Ship Date']).dt.strftime('%Y-%m-%d')\n",
    "    session.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.{table} (\n",
    "        region TEXT,\n",
    "        country TEXT,\n",
    "        item_type TEXT,\n",
    "        sales_channel TEXT,\n",
    "        order_priority TEXT,\n",
    "        order_date TEXT,\n",
    "        order_id BIGINT PRIMARY KEY,\n",
    "        ship_date TEXT,\n",
    "        units_sold INT,\n",
    "        unit_price FLOAT,\n",
    "        unit_cost FLOAT,\n",
    "        total_revenue FLOAT,\n",
    "        total_cost FLOAT,\n",
    "        total_profit FLOAT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    insert_query = session.prepare(f\"\"\"\n",
    "    INSERT INTO {keyspace}.{table} (\n",
    "        region, country, item_type, sales_channel, order_priority,\n",
    "        order_date, order_id, ship_date, units_sold, unit_price,\n",
    "        unit_cost, total_revenue, total_cost, total_profit\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        session.execute(insert_query, (\n",
    "            row['Region'], row['Country'], row['Item Type'], row['Sales Channel'],\n",
    "            row['Order Priority'], row['Order Date'], row['Order ID'], row['Ship Date'],\n",
    "            row['UnitsSold'], row['UnitPrice'], row['UnitCost'],\n",
    "            row['TotalRevenue'], row['TotalCost'], row['TotalProfit']\n",
    "        ))\n",
    "\n",
    "    print(\"CSV data successfully loaded into Cassandra!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc163868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to extract data\n",
    "def extract_data(session, keyspace, table):\n",
    "    query = f\"SELECT * FROM {keyspace}.{table}\"\n",
    "    rows = session.execute(query)\n",
    "    data = [row._asdict() for row in rows]\n",
    "    df1 = pd.DataFrame(data)\n",
    "    print('Data Extracted Successfully!')\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e39cdb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def add_audit_columns(df1: pd.DataFrame) -> pd.DataFrame:\n",
    "    try:\n",
    "        df1['ingestion_date'] = datetime.now()\n",
    "        return df1\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08094e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trims leading and trailing spaces from all string columns in the DataFrame.\n",
    "def trim_string_data(df1: pd.DataFrame) -> pd.DataFrame:\n",
    "    try:\n",
    "        for col in df1.select_dtypes(include=['object', 'string']).columns:\n",
    "            df1[col] = df1[col].str.strip()\n",
    "        return df1\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa0e50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert columtypes\n",
    "schema_mapping = { \n",
    "                    'order_date': 'datetime64[ns]',  \n",
    "                    'ship_date': 'datetime64[ns]',   \n",
    "                  }\n",
    "def convert_column_types(df1: pd.DataFrame, schema_mapping: dict) -> pd.DataFrame:\n",
    "    try:\n",
    "        for column_name, target_type in schema_mapping.items():\n",
    "            if column_name in df1.columns:\n",
    "                df1[column_name] = pd.to_datetime(df1[column_name], errors='coerce')\n",
    "        return df1\n",
    "    except Exception as e:\n",
    "        print(f\"Error in convert_column_types: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dddb3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.util import Date\n",
    "# Helper function to convert Cassandra Date to datetime\n",
    "def convert_cassandra_date_to_datetime(cassandra_date):\n",
    "    if isinstance(cassandra_date, Date):\n",
    "        return datetime.strptime(str(cassandra_date), '%Y-%m-%d')\n",
    "    return cassandra_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a2084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataframe(df1: pd.DataFrame) -> pd.DataFrame:\n",
    "        try:\n",
    "            # Cleaning the column names\n",
    "            df1.columns = [col.lower().replace(' ', '_') for col in df1.columns]\n",
    "            # Drop duplicates\n",
    "            df1 = df1.drop_duplicates()\n",
    "            #dropping null values\n",
    "            df1 = df1.dropna()\n",
    "            # adding the ingestion_date column\n",
    "            df1['ingestion_date'] = pd.to_datetime('now')\n",
    "            # Convert columns\n",
    "            date_columns = ['order_date', 'ship_date']\n",
    "            for col in date_columns:\n",
    "                if col in df1.columns:\n",
    "                    df1[col] = df1[col].apply(convert_cassandra_date_to_datetime)\n",
    "            # Convert column types\n",
    "            df1 = convert_column_types(df1, schema_mapping)\n",
    "            # Trimming string columns data\n",
    "            str_col= df1.select_dtypes(include=['object']).columns\n",
    "            for col in str_col:\n",
    "                df1[col] = df1[col].str.strip()\n",
    "            return df1\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in standardize_dataframe: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe69216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_silver_data(session, df_silver):\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS finalsales.silversales (\n",
    "        order_id BIGINT PRIMARY KEY,\n",
    "        country TEXT,\n",
    "        item_type TEXT,\n",
    "        order_date DATE,\n",
    "        order_priority TEXT,\n",
    "        region TEXT,\n",
    "        sales_channel TEXT,\n",
    "        ship_date DATE,\n",
    "        total_cost FLOAT,\n",
    "        total_profit FLOAT,\n",
    "        total_revenue FLOAT,\n",
    "        unit_cost FLOAT,\n",
    "        unit_price FLOAT,\n",
    "        units_sold INT,\n",
    "        ingestion_date TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "    session.execute(create_table_query)\n",
    "\n",
    "    insert_query = session.prepare(\"\"\"\n",
    "    INSERT INTO finalsales.silversales (\n",
    "        order_id, country, item_type, order_date, order_priority, \n",
    "        region, sales_channel, ship_date, total_cost, total_profit, \n",
    "        total_revenue, unit_cost, unit_price, units_sold, ingestion_date\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "\n",
    "    for _, row in df_silver.iterrows():\n",
    "        session.execute(insert_query, (\n",
    "            row['order_id'], row['country'], row['item_type'], row['order_date'], row['order_priority'],\n",
    "            row['region'], row['sales_channel'], row['ship_date'], row['total_cost'], row['total_profit'],\n",
    "            row['total_revenue'], row['unit_cost'], row['unit_price'], row['units_sold'], row['ingestion_date']\n",
    "        ))\n",
    "\n",
    "    print(\"Data inserted into the silversales table successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a084c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold1(session, keyspace):\n",
    "    # Sales Summary by Region\n",
    "    session.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.sales_by_region (\n",
    "        region TEXT PRIMARY KEY,\n",
    "        total_revenue FLOAT,\n",
    "        total_cost FLOAT,\n",
    "        total_profit FLOAT,\n",
    "        units_sold INT\n",
    "    )\n",
    "    \"\"\")  \n",
    "\n",
    "    region_agg = df_silver.groupby('region').agg(\n",
    "        total_revenue=('total_revenue', 'sum'),\n",
    "        total_cost=('total_cost', 'sum'),\n",
    "        total_profit=('total_profit', 'sum'),\n",
    "        units_sold=('units_sold', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    insert_query_region = f\"\"\"\n",
    "    INSERT INTO {keyspace}.sales_by_region \n",
    "    (region, total_revenue, total_cost, total_profit, units_sold) \n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    \n",
    "    prepared_query = session.prepare(insert_query_region)\n",
    "    \n",
    "    for _, row in region_agg.iterrows():\n",
    "        session.execute(prepared_query, (\n",
    "            row['region'], row['total_revenue'], row['total_cost'], \n",
    "            row['total_profit'], row['units_sold']\n",
    "        ))\n",
    "\n",
    "    print(\"Sales Summary by Region inserted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18b2909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold2(session, keyspace):\n",
    "    # Sales Summary by Product (Item Type)\n",
    "    session.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.sales_by_product (\n",
    "        item_type TEXT PRIMARY KEY,\n",
    "        total_revenue FLOAT,\n",
    "        total_cost FLOAT,\n",
    "        total_profit FLOAT,\n",
    "        units_sold INT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    product_agg = df_silver.groupby('item_type').agg(\n",
    "        total_revenue=('total_revenue', 'sum'),\n",
    "        total_cost=('total_cost', 'sum'),\n",
    "        total_profit=('total_profit', 'sum'),\n",
    "        units_sold=('units_sold', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    insert_query_product = f\"\"\"\n",
    "    INSERT INTO {keyspace}.sales_by_product \n",
    "    (item_type, total_revenue, total_cost, total_profit, units_sold) \n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "\n",
    "    prepared_query = session.prepare(insert_query_product)\n",
    "    \n",
    "    for _, row in product_agg.iterrows():\n",
    "        session.execute(prepared_query, (\n",
    "            row['item_type'], row['total_revenue'], row['total_cost'], \n",
    "            row['total_profit'], row['units_sold']\n",
    "        ))\n",
    "\n",
    "    print(\"Sales Summary by Product inserted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c029bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold3(session, keyspace):\n",
    "    # Sales Summary by Order Priority\n",
    "    session.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.sales_by_priority (\n",
    "        order_priority TEXT PRIMARY KEY,\n",
    "        total_revenue FLOAT,\n",
    "        total_cost FLOAT,\n",
    "        total_profit FLOAT,\n",
    "        units_sold INT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    priority_agg = df_silver.groupby('order_priority').agg(\n",
    "        total_revenue=('total_revenue', 'sum'),\n",
    "        total_cost=('total_cost', 'sum'),\n",
    "        total_profit=('total_profit', 'sum'),\n",
    "        units_sold=('units_sold', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    insert_query_priority = f\"\"\"\n",
    "    INSERT INTO {keyspace}.sales_by_priority \n",
    "    (order_priority, total_revenue, total_cost, total_profit, units_sold) \n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "\n",
    "    prepared_query = session.prepare(insert_query_priority)\n",
    "    \n",
    "    for _, row in priority_agg.iterrows():\n",
    "        session.execute(prepared_query, (\n",
    "            row['order_priority'], row['total_revenue'], row['total_cost'], \n",
    "            row['total_profit'], row['units_sold']\n",
    "        ))\n",
    "\n",
    "    print(\"Sales Summary by Order Priority inserted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96a8400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully loaded into Cassandra!\n",
      "Data Extracted Successfully!\n",
      "Data inserted into the silversales table successfully.\n",
      "Sales Summary by Region inserted successfully.\n",
      "Sales Summary by Product inserted successfully.\n",
      "Sales Summary by Order Priority inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    session,cluster=connect_to_cassandra()\n",
    "    #data load -Bronze Level\n",
    "    df=pd.read_csv(\"https://raw.githubusercontent.com/gchandra10/filestorage/main/sales_100.csv\")\n",
    "    keyspace='finalsales'\n",
    "    table='bronzesales'\n",
    "    #loading raw data in to cassandea Bronze table\n",
    "    load_data(session,keyspace,table,df)\n",
    "    #retrieving data from bronzesales table\n",
    "    df1 = extract_data(session, keyspace, table)\n",
    "    # Clean and standardize the DataFrame\n",
    "    df_silver = standardize_dataframe(df1)\n",
    "    #loading Silver Data into cassandra\n",
    "    load_silver_data(session, df_silver)\n",
    "    #Creating Gold tables\n",
    "    gold1(session,keyspace)\n",
    "    gold2(session,keyspace)\n",
    "    gold3(session,keyspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73837c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Gold table data\n",
    "from tabulate import tabulate\n",
    "def extract_gold_table(session, keyspace, table_name):\n",
    "    try:\n",
    "        query = f\"SELECT * FROM {keyspace}.{table_name}\"\n",
    "        rows = session.execute(query)\n",
    "        data = [row._asdict() for row in rows]\n",
    "        df_gold = pd.DataFrame(data)\n",
    "        if df_gold.empty:\n",
    "            print(f\"No data found in the {table_name} table.\")\n",
    "        else:\n",
    "            print(f\"\\n--- {table_name} ---\")\n",
    "            print(tabulate(df_gold, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "        return df_gold\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data from {table_name}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "975d41d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- sales_by_region ---\n",
      "+-----------------------------------+------------+--------------+---------------+------------+\n",
      "|              region               | total_cost | total_profit | total_revenue | units_sold |\n",
      "+-----------------------------------+------------+--------------+---------------+------------+\n",
      "|       Australia and Oceania       | 7224318.0  |  3486940.0   |  10711258.0   |   42328    |\n",
      "|              Europe               | 23697468.0 |  11267281.0  |  34964748.0   |   121002   |\n",
      "|   Middle East and North Africa    | 18250866.0 |  6514262.0   |  24765128.0   |   60376    |\n",
      "| Central America and the Caribbean | 13318535.0 |  4252300.0   |  17570836.0   |   53641    |\n",
      "|               Asia                | 22090916.0 |  6749896.0   |  28840812.0   |   113129   |\n",
      "|        Sub-Saharan Africa         | 16573546.0 |  7651892.0   |  24225438.0   |   92606    |\n",
      "|           North America           | 2207136.0  |  1404621.5   |   3611757.5   |   11728    |\n",
      "+-----------------------------------+------------+--------------+---------------+------------+\n",
      "\n",
      "--- sales_by_product ---\n",
      "+-----------------+--------------+---------------+---------------+------------+\n",
      "|    item_type    |  total_cost  | total_profit  | total_revenue | units_sold |\n",
      "+-----------------+--------------+---------------+---------------+------------+\n",
      "|    Household    |  28966406.0  |   9552677.0   |  38519084.0   |   57640    |\n",
      "| Office Supplies |  22475638.0  |   5405267.5   |  27880904.0   |   42814    |\n",
      "|   Vegetables    |  669972.25   | 465141.84375  |  1135114.125  |    7368    |\n",
      "|     Snacks      | 1400894.875  |   792747.75   |  2193642.75   |   14377    |\n",
      "|  Personal Care  |  2212680.0   |  978467.6875  |  3191147.75   |   39045    |\n",
      "|      Meat       |  18393870.0  |   2884996.5   |  21278866.0   |   50437    |\n",
      "|     Fruits      | 456166.40625 | 158867.203125 |  615033.625   |   65920    |\n",
      "|    Beverages    |  1437098.75  |  707925.9375  |  2145024.75   |   45206    |\n",
      "|     Cereal      |  5360827.5   |  4055295.75   |   9416123.0   |   45776    |\n",
      "|    Cosmetics    |  17302624.0  |  11424476.0   |  28727100.0   |   65707    |\n",
      "|    Baby Food    |  3247704.25  |  1952859.875  |   5200564.0   |   20372    |\n",
      "|     Clothes     |  1438904.25  |  2948469.25   |   4387373.5   |   40148    |\n",
      "+-----------------+--------------+---------------+---------------+------------+\n",
      "\n",
      "--- sales_by_priority ---\n",
      "+----------------+------------+--------------+---------------+------------+\n",
      "| order_priority | total_cost | total_profit | total_revenue | units_sold |\n",
      "+----------------+------------+--------------+---------------+------------+\n",
      "|       C        | 25044636.0 |  7649023.0   |  32693660.0   |   92171    |\n",
      "|       M        | 34786864.0 |  14607042.0  |  49393908.0   |   161306   |\n",
      "|       H        | 27728600.0 |  11910944.0  |  39639544.0   |   121706   |\n",
      "|       L        | 15802683.0 |  7160182.5   |  22962866.0   |   119627   |\n",
      "+----------------+------------+--------------+---------------+------------+\n"
     ]
    }
   ],
   "source": [
    "tables=['sales_by_region','sales_by_product','sales_by_priority']\n",
    "for i in tables:\n",
    "    extract_gold_table(session,keyspace,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0af5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown the cluster\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
